{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e06a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import markdown\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prs = Presentation(\"BaseballCard.pptx\")\n",
    "# # bbcard_entity_layout = prs.slide_layouts[7]\n",
    "# # slide = prs.slides.add_slide(bbcard_entity_layout)\n",
    "# # title = slide.shapes.title\n",
    "# # # subtitle = slide.placeholders[1]\n",
    "\n",
    "# # title.text = \"Hello, World!\"\n",
    "# # subtitle.text = \"python-pptx was here!\"\n",
    "\n",
    "# prs.save('BlankBBCard.pptx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1db31e6",
   "metadata": {},
   "source": [
    "### Read in Obsidian files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "428f6dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the Obsidian directory to search: (It must be in this directory)\n",
      "Investigation\n",
      "Investigation\n"
     ]
    }
   ],
   "source": [
    "case_dir = (input(\"Enter the name of the Obsidian directory to search: (It must be in this directory)\\n\")\n",
    "           .strip())\n",
    "print(case_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76c0e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the subdirectory with entities to create target profiles for:\n",
      "['Assets', 'Identifiers', 'People', 'Places']\n",
      "People\n",
      "People\n"
     ]
    }
   ],
   "source": [
    "case_sub_dirs = [i for i in os.listdir(case_dir) if not \".\" in i]\n",
    "case_sub_dirs\n",
    "\n",
    "target_dir = (input(f\"Choose the subdirectory with entities to create target profiles for:\\n{case_sub_dirs}\\n\")\n",
    "             .strip())\n",
    "print(target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8949b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arron Gaines.md', 'Elsie Graves.md', 'Jan Jackson.md', 'Kevin Ellison.md', 'Wilfredo Goodman.md']\n"
     ]
    }
   ],
   "source": [
    "entities_to_parse = []\n",
    "\n",
    "for file in os.listdir(f\"{case_dir}/{target_dir}\"):\n",
    "    if file.endswith(\"md\"):\n",
    "        entities_to_parse.append(file)\n",
    "\n",
    "print(entities_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99167929",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entity_data = {}\n",
    "\n",
    "# Read each markdown file in and convert to HTML then convert to soup\n",
    "for i in entities_to_parse[0:1]:\n",
    "    entity_name = i.replace(\".md\", \"\")\n",
    "    entity_data[entity_name] = {}\n",
    "    \n",
    "    html = None\n",
    "    with open(f\"{case_dir}/{target_dir}/{i}\", \"r\", encoding=\"utf-8\") as f:\n",
    "#         print(f)\n",
    "        text = f.read()\n",
    "    html = markdown.markdown(text)\n",
    "    soup = bs(html)\n",
    "    \n",
    "    entity_data[entity_name][\"soup\"] = soup\n",
    "\n",
    "# entity_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f6cda",
   "metadata": {},
   "source": [
    "For each person entity, want:\n",
    "- picture (path to)\n",
    "- summary details (maybe?)\n",
    "- associates list\n",
    "- identifiers list (email, phones, etc.)\n",
    "- locations list (home, work, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ddc5b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example item using first entity (for testing)\n",
    "ex = entity_data[\"Arron Gaines\"]\n",
    "# ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49b58d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find picture, get filename, reconstruct path, add to dict\n",
    "\n",
    "# Determine picture filename and path\n",
    "pic_tag = soup.find(\"code\", text=\"Picture\").next_sibling.string # relies on embedded picture being next\n",
    "# print((type(pic_tag)))\n",
    "# print(pic_tag)\n",
    "\n",
    "pic_filename = re.search(\"([A-Z\\_]{1,}\\.[0-9A-Z]{1,7})\", pic_tag, re.IGNORECASE)[1]\n",
    "# print(pic_filename)\n",
    "\n",
    "pic_path = f\"Assets/{pic_filename}\" # need to check ext is png, jpg, etc.\n",
    "# print(pic_path)\n",
    "\n",
    "ex[\"picture_path\"] = pic_path\n",
    "# ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddb78f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'soup': <html><body><hr/>\n",
       " <p>tags:\n",
       "   - Person_Of_Interest</p>\n",
       " <hr/>\n",
       " <p><code>Picture</code> \n",
       " ![[Arron_Gaines.jpg | 300]]</p>\n",
       " <h2>Summary</h2>\n",
       " <ul>\n",
       " <li><code>Detail</code> Subject is suspected of running a phishing campaign {.personSummary}</li>\n",
       " <li><code>Detail</code> Subject believed to be working with [[Kevin Ellison]] { .personSummary }</li>\n",
       " <li><code>Detail</code> Phishing victims include: [[Elsie Graves]], [[Wilfredo Goodman]], and [[Jan Jackson]]</li>\n",
       " </ul>\n",
       " <h2>Associates</h2>\n",
       " <ul>\n",
       " <li>works with: [[Kevin Ellison]] <code>Associate</code></li>\n",
       " </ul>\n",
       " <h2>Identifiers</h2>\n",
       " <ul>\n",
       " <li><code>Identifier</code> uses: [[mglanman@mycbt(.)me]]{.identifierEmail}</li>\n",
       " <li><code>Identifier</code> uses: [[+1472-217-7096]] {.identifierPhone}</li>\n",
       " <li><code>Identifier</code> possibly uses: 5712223344</li>\n",
       " </ul>\n",
       " <h2>Locations:</h2>\n",
       " <ul>\n",
       " <li><code>Residence Name</code> [[350 Central Park West Apartments]]{.locationResidenceName}</li>\n",
       " <li><code>Residence Address</code> 350 Central Park West, New York, NY 10025{.locationResidenceAddress}</li>\n",
       " <li><code>Residence Coordinates</code> 40.79078819123121, -73.96568568759587</li>\n",
       " <li><code>Work Name</code> undetermined organization at [[30 Rockefeller Plaza]]</li>\n",
       " <li><code>Work Address</code> 30 Rockefeller Plaza, New York, NY 10112</li>\n",
       " <li><code>Work Coordinates</code> 40.758941635700246, -73.97900684718394</li>\n",
       " </ul></body></html>}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Find all list item tags\n",
    "# all_li_tags = soup.find_all(\"li\")\n",
    "# # print(all_li_tags)\n",
    "\n",
    "# # # IDEA TWO\n",
    "# # Filter li tag list for only items with identifier code tag\n",
    "# def find_identifier_tags(x):\n",
    "#     code_tag = None\n",
    "#     try:\n",
    "#         code_tag = x.find(\"code\")\n",
    "#         return True if \"Identifier\" in code_tag.get_text() else False\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "    \n",
    "# tags_with_identifiers_only = list(filter(lambda x: find_identifier_tags(x), all_li_tags))\n",
    "# # print(tags_with_identifiers_only)\n",
    "\n",
    "# def extract_identifier(x):\n",
    "#     \"\"\"Match Obsidian's link format and extract characters between double square brackets\"\"\"\n",
    "# #     return re.match(\"(\\[\\[)(.*)(\\]\\])\", x)[2] # 2nd item is middle capture group\n",
    "# #     print(x)\n",
    "#     matched = None\n",
    "#     try:\n",
    "#         matched = re.match(\".*(\\[\\[)(.*)(\\]\\]).*\", x)[2]\n",
    "# #         print(\"matched: \", matched)\n",
    "#     except TypeError:\n",
    "# #         print(\"no match\")\n",
    "#         matched = x.strip()\n",
    "# #     print(\"matched: \", matched)\n",
    "#     return matched\n",
    "\n",
    "# cleaned_identifiers = list(map(lambda x: extract_identifier(x.get_text().replace(\"Identifier\", \"\")), \n",
    "#                                tags_with_identifiers_only))\n",
    "# print(cleaned_identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find all list item tags\n",
    "# all_li_tags = soup.find_all(\"li\")\n",
    "# # print(all_li_tags)\n",
    "\n",
    "# # Filter li tag list for only items with identifier attribute\n",
    "# tags_with_identifiers_only = list(filter(lambda x: \"{.identifier}\" in x.get_text(), all_li_tags))\n",
    "# # print(tags_with_identifiers_only)\n",
    "\n",
    "# # \n",
    "# def extract_identifier(x):\n",
    "#     \"\"\"Match Obsidian's link format and extract characters between double square brackets\"\"\"\n",
    "#     return re.match(\"(\\[\\[)(.*)(\\]\\])\", x)[2] # 2nd item is middle capture group\n",
    "\n",
    "# cleaned_identifiers = list(map(lambda x: extract_identifier(x.get_text()), tags_with_identifiers_only))\n",
    "# print(cleaned_identifiers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
